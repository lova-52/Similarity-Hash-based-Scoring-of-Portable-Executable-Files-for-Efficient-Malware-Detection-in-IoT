import ssdeep
import csv
from tqdm import tqdm

def calculate_esf(cfi, dataset_I, dataset_II):
    esf = {}
    # Loop through all files in Dataset II
    for index, row in tqdm(dataset_II.iterrows(), total=len(dataset_II), desc='Processing Dataset II'):
        # Get file hashes from Dataset II
        Imp_H = row['Imp_H']
        Pe_H = row['Pe_H']
        Sd_H = row['Sd_H']
        RSd_H = row['RSd_H']
    
        # Query Dataset I for each hash type and update HFlag_set
        HFlag_set = {'Imp_H': set(), 'Pe_H': set(), 'Sd_H': set(), 'RSd_H': set()}
    
        # Query Dataset I for ImpHash
        result = dataset_I.loc[dataset_I['Imp_H'] == Imp_H, 'File_name'].values
        if result.size > 0:
            HFlag_set['Imp_H'].add(cfi['Imp_H'])
    
        # Query Dataset I for PeHash
        result = dataset_I.loc[dataset_I['Pe_H'] == Pe_H, 'File_name'].values
        if result.size > 0:
            HFlag_set['Pe_H'].add(cfi['Pe_H'])
    
        # Calculate maximum similarity percentage for Sd_H
        max_similarity_sd = 0
        for sd_hash in dataset_I['Sd_H']:
            similarity_percentage = ssdeep.compare(sd_hash, Sd_H)
            if similarity_percentage > max_similarity_sd:
                max_similarity_sd = similarity_percentage
        
        # Calculate maximum similarity percentage for RSd_H
        max_similarity_rsd = 0
        for rsd_hash in dataset_I['RSd_H']:
            similarity_percentage = ssdeep.compare(rsd_hash, RSd_H)
            if similarity_percentage > max_similarity_rsd:
                max_similarity_rsd = similarity_percentage
    
        # Compute ESF values
        esf_value = {}
        esf_value['Imp_H'] = max(HFlag_set['Imp_H']) if HFlag_set['Imp_H'] else 0
        esf_value['Pe_H'] = max(HFlag_set['Pe_H']) if HFlag_set['Pe_H'] else 0
        esf_value['Sd_H'] = cfi['Sd_H'] * max_similarity_sd
        esf_value['RSd_H'] = cfi['RSd_H'] * max_similarity_rsd
    
        # Add ESF values to the esf dictionary
        esf[row['File_name']] = esf_value
    
    # Write results to a CSV file
    with open('esf_results.csv', 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['File_name', 'Imp_H_ESF', 'Pe_H_ESF', 'Sd_H_ESF', 'RSd_H_ESF'])
        for file_name, esf_value in esf.items():
            writer.writerow([file_name, esf_value['Imp_H'], esf_value['Pe_H'], esf_value['Sd_H'], esf_value['RSd_H']])

def fuzzy_logic_algebraic_sum(det_rates, cfi, dataset_I, dataset_II):
    esf = calculate_esf(cfi, dataset_I, dataset_II)
    # calculate degree of belief for Malicious hypothesis
    dob_m = 1
    for method in esf.keys():
        print(dob_m, "*= ", 1-esf[method])
        dob_m *= 1 - esf[method]
    dob_m = 1 - dob_m
    print(dob_m)

    # calculate degree of belief for Benign hypothesis
    dob_b = 1
    for method in esf.keys():
        dob_b *= esf[method]
    dob_b = 1 - dob_b
    print(dob_b)

    # calculate degree of belief for Suspicious hypothesis
    dob_se = 1 - dob_m - dob_b
    
    # calculate overall degree of belief using Fuzzy Logic and the algebraic sum formula
    o_dob = dob_m + dob_b - dob_m * dob_b
    
    return o_dob

def certainty_factor_algebraic_sum(det_rates, cfi, dataset_I, dataset_II):
    esf = calculate_esf(cfi, dataset_I, dataset_II)
 
    # calculate degree of belief for Malicious hypothesis
    dob_m = 1
    for method in esf.keys():
        dob_m *= 1 - esf[method]
    dob_m = 1 - dob_m
    
    # calculate degree of belief for Benign hypothesis
    dob_b = 1
    for method in esf.keys():
        dob_b *= esf[method]
    dob_b = 1 - dob_b
    
    # calculate degree of belief for Suspicious hypothesis
    dob_se = 1 - dob_m - dob_b
    
    # calculate overall degree of belief using the Certainty Factor model
    dob_common = max(dob_m, dob_b, dob_se)
    if dob_common == 0:
        o_dob = 0
    else:
        # calculate overall degree of belief using the Archimedean t-conorm formula
        o_dob = (dob_m + dob_b) / (1 + dob_m * dob_b)
    
    return o_dob

def calculate_tlbsa(det_rates, cfi, dataset_I, dataset_II):
    #fuzzy_sum = fuzzy_logic_algebraic_sum(det_rates, cfi, dataset_I, dataset_II)
    #certainty_factor_sum = certainty_factor_algebraic_sum(det_rates, cfi, dataset_I, dataset_II)
    #print("Fuzzy logic algebraic sum = ", fuzzy_sum)
    #print("Certainty Factor Model algebraic sum = ", certainty_factor_sum)
    esf = calculate_esf(cfi, dataset_I, dataset_II)

