import ssdeep
import csv
from tqdm import tqdm
import pandas as pd

def calculate_esf(cfi, dataset_I, dataset_II):
    #Initialize ESF holder
    esf = {}
    # Loop through all files in Dataset II
    for index, row in tqdm(dataset_II.iterrows(), total=len(dataset_II), desc='Processing Dataset II'):
        # Get file hashes from Dataset II
        Imp_H = row['Imp_H']
        Pe_H = row['Pe_H']
        Sd_H = row['Sd_H']
        RSd_H = row['RSd_H']
    
        # Query Dataset I for each hash type and update HFlag_set
        HFlag_set = {'Imp_H': set(), 'Pe_H': set(), 'Sd_H': set(), 'RSd_H': set()}
    
        # Query Dataset I for ImpHash
        result = dataset_I.loc[dataset_I['Imp_H'] == Imp_H, 'File_name'].values
        if result.size > 0:
            HFlag_set['Imp_H'].add(cfi['Imp_H'])
    
        # Query Dataset I for PeHash
        result = dataset_I.loc[dataset_I['Pe_H'] == Pe_H, 'File_name'].values
        if result.size > 0:
            HFlag_set['Pe_H'].add(cfi['Pe_H'])
    
        # Calculate maximum similarity percentage for Sd_H
        max_similarity_sd = 0
        for sd_hash in dataset_I['Sd_H']:
            similarity_percentage = ssdeep.compare(sd_hash, Sd_H)
            if similarity_percentage > max_similarity_sd:
                max_similarity_sd = similarity_percentage
        
        # Calculate maximum similarity percentage for RSd_H
        max_similarity_rsd = 0
        for rsd_hash in dataset_I['RSd_H']:
            similarity_percentage = ssdeep.compare(rsd_hash, RSd_H)
            if similarity_percentage > max_similarity_rsd:
                max_similarity_rsd = similarity_percentage
    
        # Compute ESF values
        esf_value = {}
        esf_value['Imp_H'] = max(HFlag_set['Imp_H']) if HFlag_set['Imp_H'] else 0
        esf_value['Pe_H'] = max(HFlag_set['Pe_H']) if HFlag_set['Pe_H'] else 0
        esf_value['Sd_H'] = cfi['Sd_H'] * max_similarity_sd
        esf_value['RSd_H'] = cfi['RSd_H'] * max_similarity_rsd
    
        # Add ESF values to the esf dictionary
        esf[row['File_name']] = esf_value
    
    # Write results to a CSV file
    with open('esf_results.csv', 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['File_name', 'Imp_H_ESF', 'Pe_H_ESF', 'Sd_H_ESF', 'RSd_H_ESF'])
        for file_name, esf_value in esf.items():
            writer.writerow([file_name, esf_value['Imp_H'], esf_value['Pe_H'], esf_value['Sd_H'], esf_value['RSd_H']])

def calculate_degree_of_belief():
    esf_file = "esf_results.csv"
    df = pd.read_csv(esf_file)  # Read the CSV file containing the ESF values

    #Fuzzy logic
    #a * b * c * d = a + b + c + d - (a * b) - (a * c) - (a * d) - (b * c) - (b * d) - (c * d) + (a * b * c) + (a * b * d) + (a * c * d) + (b * c * d) - (a * b * c * d)
    df['FLM'] = df.apply(lambda row: row['Imp_H_ESF'] + row['Pe_H_ESF'] + row['Sd_H_ESF'] + row['RSd_H_ESF'] 
                                      - (row['Imp_H_ESF'] * row['Pe_H_ESF']) - (row['Imp_H_ESF'] * row['Sd_H_ESF'])
                                      - (row['Imp_H_ESF'] * row['RSd_H_ESF']) - (row['Pe_H_ESF'] * row['Sd_H_ESF'])
                                      - (row['Pe_H_ESF'] * row['RSd_H_ESF']) - (row['Sd_H_ESF'] * row['RSd_H_ESF'])
                                      + (row['Imp_H_ESF'] * row['Pe_H_ESF'] * row['Sd_H_ESF'])
                                      + (row['Imp_H_ESF'] * row['Pe_H_ESF'] * row['RSd_H_ESF'])
                                      + (row['Imp_H_ESF'] * row['Sd_H_ESF'] * row['RSd_H_ESF'])
                                      + (row['Pe_H_ESF'] * row['Sd_H_ESF'] * row['RSd_H_ESF'])
                                      - (row['Imp_H_ESF'] * row['Pe_H_ESF'] * row['Sd_H_ESF'] * row['RSd_H_ESF']), axis=1)

    #Certainty Factor model
    #a * b * c * d = (a + b + c + d) /
    #       (1 + a * b + a * c + a * d + b * c + b * d + c * d + a * b * c + a * b * d + a * c * d + b * c * d + a * b * c * d)
    df['CFM'] = df.apply(lambda row: (row['Imp_H_ESF'] + row['Pe_H_ESF'] + row['Sd_H_ESF'] + row['RSd_H_ESF']) /
                                        (1 + row['Imp_H_ESF'] * row['Pe_H_ESF'] + row['Imp_H_ESF'] * row['Sd_H_ESF']
                                        + row['Imp_H_ESF'] * row['RSd_H_ESF'] + row['Pe_H_ESF'] * row['Sd_H_ESF']
                                        + row['Pe_H_ESF'] * row['RSd_H_ESF'] + row['Sd_H_ESF'] * row['RSd_H_ESF']
                                        + row['Imp_H_ESF'] * row['Pe_H_ESF'] * row['Sd_H_ESF']
                                        + row['Imp_H_ESF'] * row['Pe_H_ESF'] * row['RSd_H_ESF']
                                        + row['Imp_H_ESF'] * row['Sd_H_ESF'] * row['RSd_H_ESF']
                                        + row['Pe_H_ESF'] * row['Sd_H_ESF'] * row['RSd_H_ESF']
                                        + row['Imp_H_ESF'] * row['Pe_H_ESF'] * row['Sd_H_ESF'] * row['RSd_H_ESF']), axis=1)

    df.to_csv(esf_file, index=False)  # Write the updated DataFrame back to the CSV file

def calculate_tlbsa(cfi, dataset_I, dataset_II):
    #esf = calculate_esf(cfi, dataset_I, dataset_II)
    calculate_degree_of_belief()

